{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Knowledge Proficiency Tracing model (KPT) and Exercise-correlated KPT (EKPT)\n",
    "\n",
    "This notebook will show you how to train and use the KPT and EKPT.\n",
    "First, we will show how to get the data (here we use assistment-2009-2010-skill as the dataset).\n",
    "Then we will show how to train a KPT and EKPT, and perform the parameters persistence.\n",
    "At last, we will show how to load the parameters from the file and evaluate on the test dataset.\n",
    "\n",
    "The script version could be found in [KPT.py](KPT.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Before we process the data, we need to first acquire the dataset which is shown in [prepare_dataset.ipynb](prepare_dataset.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7577, 20) 167068\n",
      "number of students is 3559, number of problems is 7577\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the original data, take students' first-attempt responses, selecte the 20 most frequent knowledge concepts\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "origin_data = []\n",
    "non_repeat_data = defaultdict(dict) \n",
    "skill_count = defaultdict(int)\n",
    "with open(\"../../data/2009_skill_builder_data_corrected/skill_builder_data_corrected.csv\", encoding='utf-8',  errors='ignore') as file:\n",
    "    next(file)\n",
    "    for fileline in file:\n",
    "        row = fileline.split(',')\n",
    "        order = int(row[0])\n",
    "        stu_id = int(row[2])\n",
    "        prob_id = int(row[4])\n",
    "        correct = int(row[6])\n",
    "        answer_type = row[10]\n",
    "        try:\n",
    "            skill_id = int(row[16])\n",
    "            if answer_type != 'open_response': \n",
    "                if prob_id not in non_repeat_data[stu_id]:\n",
    "                    origin_data.append([order, stu_id, prob_id, correct, skill_id])\n",
    "                    skill_count[skill_id] += 1\n",
    "                    non_repeat_data[stu_id][prob_id] = [order, stu_id, prob_id, correct, skill_id]\n",
    "                else:  # not the first attempt\n",
    "                    his_att = non_repeat_data[stu_id][prob_id]\n",
    "                    idx = origin_data.index(his_att)\n",
    "                    if his_att[0] > order:\n",
    "                        origin_data[idx] = [order, stu_id, prob_id, correct, skill_id]\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "know_num = 20  # 20 most frequent knowledge\n",
    "skill_20 = sorted(skill_count, key=lambda x:skill_count[x], reverse=True)[:know_num]  \n",
    "q_m = []  # Q-matrix\n",
    "stu_dict, prob_dict = {},{}\n",
    "data = []\n",
    "stu_idx, prob_idx = 0, 0\n",
    "for record in origin_data:\n",
    "    order, stu, prob, answer, skill = record\n",
    "    if skill in skill_20:\n",
    "        skill_new_idx = skill_20.index(skill)\n",
    "        if stu not in stu_dict:\n",
    "            stu_dict[stu] = stu_idx\n",
    "            stu_idx += 1\n",
    "        if prob not in prob_dict:\n",
    "            prob_dict[prob] = prob_idx\n",
    "            prob_idx += 1\n",
    "            q_m_row = np.zeros(shape=know_num)\n",
    "            q_m_row[skill_new_idx] = 1\n",
    "            q_m.append(q_m_row)\n",
    "        data.append([stu_dict[stu], prob_dict[prob], answer, order])\n",
    "q_m = np.array(q_m)\n",
    "data = sorted(data, key=lambda x:x[3])\n",
    "print(q_m.shape, len(data))\n",
    "print(\"number of students is %d, number of problems is %d\" % (stu_idx, prob_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_id': 393, 'item_id': 2857, 'score': 1} {'user_id': 21, 'item_id': 5152, 'score': 1}\n"
     ]
    }
   ],
   "source": [
    "# Preprocess data into multiple time windows, split train/test data\n",
    "time_window_num = 7\n",
    "\n",
    "stu_data = defaultdict(list)\n",
    "for record in data:\n",
    "    stu, prob, rating, time = record\n",
    "    stu_data[int(stu)].append({'user_id': int(stu), 'item_id': int(prob), 'score': rating})\n",
    "\n",
    "# split dataset\n",
    "train_logs, test_logs = [], []\n",
    "for t in range(time_window_num):\n",
    "    t_train = []\n",
    "    for stu in stu_data:\n",
    "        split_len = int(len(stu_data[stu])/time_window_num)\n",
    "        if t != time_window_num-1:\n",
    "            t_train += stu_data[stu][t*split_len:(t+1)*split_len]\n",
    "        else:\n",
    "            for j in range(t*split_len, len(stu_data[stu])):\n",
    "                if np.random.random() < 0.5:\n",
    "                    t_train.append(stu_data[stu][j])\n",
    "                else:\n",
    "                    test_logs.append(stu_data[stu][j])\n",
    "    random.shuffle(t_train)\n",
    "    train_logs.append(t_train)\n",
    "\n",
    "with open(\"../../data/2009_skill_builder_data_corrected/train_data.json\", 'w', encoding='utf8') as file:\n",
    "    json.dump(train_logs, file, indent=4, ensure_ascii=False)\n",
    "with open(\"../../data/2009_skill_builder_data_corrected/test_data.json\", 'w', encoding='utf8') as file:\n",
    "    json.dump(test_logs, file, indent=4, ensure_ascii=False)\n",
    "np.savetxt(\"../../data/2009_skill_builder_data_corrected/q_m.csv\", q_m, delimiter=',', fmt='%d')\n",
    "\n",
    "# train_logs[0][0] is the first train log in the first Time Window\"\n",
    "print(train_logs[0][0], test_logs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from files\n",
    "\n",
    "# Q matrix\n",
    "q_m = np.loadtxt(\"../../data/2009_skill_builder_data_corrected/q_m.csv\", dtype=int, delimiter=\",\")\n",
    "prob_num, know_num = q_m.shape[0], q_m.shape[1]\n",
    "\n",
    "# training data\n",
    "with open(\"../../data/2009_skill_builder_data_corrected/train_data.json\", encoding='utf-8') as file:\n",
    "    train_set = json.load(file)\n",
    "stu_num = max([x['user_id'] for x in train_set[0]]) + 1\n",
    "time_window_num = len(train_set)\n",
    "                    \n",
    "# testing data\n",
    "with open(\"../../data/2009_skill_builder_data_corrected/test_data.json\", encoding='utf-8') as file:\n",
    "    test_set = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training and Persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:save parameters to kpt.params\n"
     ]
    }
   ],
   "source": [
    "from EduKTM import KPT\n",
    "\n",
    "cdm = KPT('KPT', q_m, stu_num, prob_num, know_num, time_window_num=time_window_num)\n",
    "\n",
    "cdm.train(train_set, epoch=2, lr=0.001, lr_b=0.0001, epsilon=1e-3, init_method='mean')\n",
    "cdm.save(\"kpt.params\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EKPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:save parameters to ekpt.params\n"
     ]
    }
   ],
   "source": [
    "cdm2 = KPT('EKPT', q_m, stu_num, prob_num, know_num, time_window_num=time_window_num)\n",
    "\n",
    "cdm2.train(train_set, epoch=2, lr=0.001, lr_b=0.0001, epsilon=1e-3, init_method='mean')\n",
    "cdm2.save(\"ekpt.params\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Loading and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:load parameters from kpt.params\n",
      "evaluating: 100%|██████████████████████████████████████████████████████████████| 16370/16370 [00:02<00:00, 7099.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For KPT, RMSE: 0.445781, MAE: 0.379456\n"
     ]
    }
   ],
   "source": [
    "cdm.load(\"kpt.params\")\n",
    "rmse, mae = cdm.eval(test_set)\n",
    "print(\"For KPT, RMSE: %.6f, MAE: %.6f\" % (rmse, mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EKPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:load parameters from ekpt.params\n",
      "evaluating: 100%|██████████████████████████████████████████████████████████████| 16370/16370 [00:02<00:00, 7576.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For EKPT, RMSE: 0.446698, MAE: 0.379953\n"
     ]
    }
   ],
   "source": [
    "cdm2.load(\"ekpt.params\")\n",
    "rmse2, mae2 = cdm2.eval(test_set)\n",
    "print(\"For EKPT, RMSE: %.6f, MAE: %.6f\" % (rmse2, mae2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
